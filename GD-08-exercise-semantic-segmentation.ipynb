{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fresh-flight",
   "metadata": {},
   "source": [
    "# [GD8]-세그멘테이션 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리를 로드합니다. \n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import  HorizontalFlip, RandomSizedCrop, Compose, OneOf, Resize\n",
    "\n",
    "def build_augmentation(is_train=True):\n",
    "    if is_train:    # 훈련용 데이터일 경우\n",
    "        return Compose([\n",
    "                    HorizontalFlip(p=0.5),    # 50%의 확률로 좌우대칭\n",
    "                    RandomSizedCrop(         # 50%의 확률로 RandomSizedCrop\n",
    "                        min_max_height=(300, 370),\n",
    "                        w2h_ratio=370/1242,\n",
    "                        height=224,\n",
    "                        width=224,\n",
    "                        p=0.5\n",
    "                        ),\n",
    "                    Resize(              # 입력이미지를 224X224로 resize\n",
    "                        width=224,\n",
    "                        height=224\n",
    "                        )\n",
    "                    ])\n",
    "    return Compose([      # 테스트용 데이터일 경우에는 224X224로 resize만 수행합니다. \n",
    "                Resize(\n",
    "                    width=224,\n",
    "                    height=224\n",
    "                    )\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.getenv('HOME')+'/aiffel/semantic_segmentation/data/training'\n",
    "\n",
    "augmentation = build_augmentation()\n",
    "input_images = glob(os.path.join(dir_path, \"image_2\", \"*.png\"))\n",
    "\n",
    "# 훈련 데이터셋에서 5개만 가져와 augmentation을 적용해 봅시다.  \n",
    "plt.figure(figsize=(12, 20))\n",
    "for i in range(5):\n",
    "    image = imread(input_images[i]) \n",
    "    image_data = {\"image\":image}\n",
    "    resized = augmentation(**image_data, is_train=False)\n",
    "    processed = augmentation(**image_data)\n",
    "    plt.subplot(5, 2, 2*i+1)\n",
    "    plt.imshow(resized[\"image\"])  # 왼쪽이 원본이미지\n",
    "    plt.subplot(5, 2, 2*i+2)\n",
    "    plt.imshow(processed[\"image\"])  # 오른쪽이 augment된 이미지\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KittiGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                dir_path,\n",
    "                batch_size = 4,\n",
    "                img_size=(224,224,3),\n",
    "                output_size=(224,224),\n",
    "                is_train=True,\n",
    "                augmentation=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.augmentation = augmentation\n",
    "        self.img_size = img_size\n",
    "        self.output_size = output_size\n",
    "        #load_dataset()을 통해서 kitti dataset의 directory path에서\n",
    "        #라벨과 이미지를 확인한다.\n",
    "        self.data = self.load_dataset()\n",
    "    def load_dataset(self):\n",
    "        # kitti dataset에서 필요한 정보(이미지 경로 및 라벨)를 directory에서 확인하고 로드하는 함수입니다.\n",
    "        # 이때 is_train에 따라 test set을 분리해서 load하도록 해야합니다.    \n",
    "        input_images = glob(os.path.join(self.dir_path, \"image_2\",\"*.png\"))\n",
    "        label_images = glob(os.path.join(self.dir_path, \"semantic\",\"*.png\"))\n",
    "        input_images.sort()\n",
    "        label_images.sort()\n",
    "        assert len(input_images) == len(label_images)\n",
    "        data = [_ for _ in zip(input_images, label_images)]\n",
    "        if self.is_train:\n",
    "            return data[:-30]\n",
    "        return data[-30:]\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.data)/self.batch_size)\n",
    "    def __getitem__(self, index):\n",
    "        #입력과 출력을 만든다.\n",
    "        #입력은 resize 및 augmentation이 적용된 input image이고\n",
    "        #출력은 semantic label이다.\n",
    "        batch_data = self.data[\n",
    "            index*self.batch_size : (index+1)*self.batch_size\n",
    "        ]\n",
    "        inputs = np.zeros([self.batch_size, *self.img_size])\n",
    "        outputs = np.zeros([self.batch_size, *self.output_size])\n",
    "        #data에서 배치만큼 가져온 것 (input과 label image가 같이 들어있다)\n",
    "        for i, data in enumerate(batch_data):\n",
    "            input_img_path, output_path = data\n",
    "            _input = imread(input_img_path)\n",
    "            _output = imread(output_path)\n",
    "            _output = (_output==7).astype(np.uint8)*1\n",
    "            data = {\n",
    "                \"image\" : _input,\n",
    "                \"mask\" : _output,\n",
    "            }\n",
    "            augmented = self.augmentation(**data)\n",
    "            inputs[i] = augmented[\"image\"]/255\n",
    "            outputs[i] = augmented[\"mask\"]\n",
    "        return inputs, outputs\n",
    "    def on_epoch_end(self):\n",
    "        #한 에폭이 끝나면 실행되는 함수이다. 학습중인 경우에 순서를 random shuffle하도록 적용하는\n",
    "        #것을 볼수 있다.\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        if self.is_train == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            return self.indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = build_augmentation()\n",
    "test_preproc = build_augmentation(is_train=False)\n",
    "\n",
    "train_generator = KittiGenerator(dir_path,\n",
    "                                augmentation=augmentation,)\n",
    "test_generator = KittiGenerator(dir_path,\n",
    "                                augmentation=test_preproc,\n",
    "                                is_train=False\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-steps",
   "metadata": {},
   "source": [
    "## 시맨틱 세그멘테이션 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-london",
   "metadata": {},
   "source": [
    "### 모델 구조 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape=(224, 224, 3)):\n",
    "    \n",
    "    n = 64\n",
    "    filters = [n, n*2, n*4, n*8, n*16]\n",
    "    \n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    conv1 = Conv2D(filters[0], 3, activation='relu', padding='same',kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(filters[0], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters[1], 3, activation='relu', padding='same',kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(filters[1], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(filters[2], 3, activation='relu', padding='same',kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(filters[2], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(filters[3], 3, activation='relu', padding='same',kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(filters[3], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(filters[4], 3, activation='relu', padding='same',kernel_initializer='he_normal')(pool4)  \n",
    "    conv5 = Conv2D(filters[4], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(filters[3], 2, activation='relu', padding='same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(drop5)) \n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(filters[3], 3, activation='relu', padding='same',kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(filters[3], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(filters[2], 2, activation='relu', padding='same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(filters[2], 3, activation='relu', padding='same',kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(filters[2], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(filters[1], 2, activation='relu', padding='same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(filters[1], 3, activation='relu', padding='same',kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(filters[1], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(filters[0], 2, activation='relu', padding='same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(filters[0], 3, activation='relu', padding='same',kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(filters[0], 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv9)  \n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv9)     \n",
    "\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, './UNet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-medline",
   "metadata": {},
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy')\n",
    "model.fit_generator(\n",
    "     generator=train_generator,\n",
    "     validation_data=test_generator,\n",
    "     steps_per_epoch=len(train_generator),\n",
    "     epochs=100,\n",
    " )\n",
    "\n",
    "model_path = dir_path + '/seg_model_unet.h5'\n",
    "model.save(model_path)  #학습한 모델을 저장해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-explanation",
   "metadata": {},
   "source": [
    "### 시맨틱 세그멘테이션 모델 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(model, preproc, image_path, output_path):\n",
    "    origin_img = imread(image_path)\n",
    "    data = {\"image\":origin_img}\n",
    "    processed = preproc(**data)\n",
    "    output = model(np.expand_dims(processed[\"image\"]/255,axis=0))\n",
    "    output = (output[0].numpy()>0.5).astype(np.uint8).squeeze(-1)*255  #0.5라는 threshold를 변경하면 도로인식 결과범위가 달라집니다.\n",
    "    output = Image.fromarray(output)\n",
    "    background = Image.fromarray(origin_img).convert('RGBA')\n",
    "    output = output.resize((origin_img.shape[1], origin_img.shape[0])).convert('RGBA')\n",
    "    output = Image.blend(background, output, alpha=0.5)\n",
    "    output.show()\n",
    "    return output\n",
    " \n",
    "\n",
    "# 완성한 뒤에는 시각화한 결과를 눈으로 확인해봅시다!\n",
    "i = 1    # i값을 바꾸면 테스트용 파일이 달라집니다. \n",
    "get_output(\n",
    "     model, \n",
    "     test_preproc,\n",
    "     image_path=dir_path + f'/image_2/00{str(i).zfill(4)}_10.png',\n",
    "     output_path=dir_path + f'./result_{str(i).zfill(3)}.png'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou_score(target, prediction):\n",
    "    intersection = np.logical_and(target, prediction)\n",
    "    union = np.logical_or(target, prediction)\n",
    "    iou_score = float(np.sum(intersection)) / float(np.sum(union))\n",
    "    print('IoU : %f' % iou_score )\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(model, preproc, image_path, output_path, label_path):\n",
    "    origin_img = imread(image_path)\n",
    "    data = {\"image\":origin_img}\n",
    "    processed = preproc(**data)\n",
    "    output = model(np.expand_dims(processed[\"image\"]/255,axis=0))\n",
    "    output = (output[0].numpy()>=0.5).astype(np.uint8).squeeze(-1)*255  #0.5라는 threshold를 변경하면 도로인식 결과범위가 달라집니다.\n",
    "    prediction = output/255   # 도로로 판단한 영역\n",
    "    \n",
    "    output = Image.fromarray(output)\n",
    "    background = Image.fromarray(origin_img).convert('RGBA')\n",
    "    output = output.resize((origin_img.shape[1], origin_img.shape[0])).convert('RGBA')\n",
    "    output = Image.blend(background, output, alpha=0.5)\n",
    "    output.show()   # 도로로 판단한 영역을 시각화!\n",
    "     \n",
    "    if label_path:   \n",
    "        label_img = imread(label_path)\n",
    "        label_data = {\"image\":label_img}\n",
    "        label_processed = preproc(**label_data)\n",
    "        label_processed = label_processed[\"image\"]\n",
    "        target = (label_processed == 7).astype(np.uint8)*1   # 라벨에서 도로로 기재된 영역\n",
    "\n",
    "        return output, prediction, target\n",
    "    else:\n",
    "        return output, prediction, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성한 뒤에는 시각화한 결과를 눈으로 확인해봅시다!\n",
    "i = 1    # i값을 바꾸면 테스트용 파일이 달라집니다. \n",
    "output, prediction, target = get_output(\n",
    "     model, \n",
    "     test_preproc,\n",
    "     image_path=dir_path + f'/image_2/00{str(i).zfill(4)}_10.png',\n",
    "     output_path=dir_path + f'./result_{str(i).zfill(3)}.png',\n",
    "     label_path=dir_path + f'/semantic/00{str(i).zfill(4)}_10.png'\n",
    " )\n",
    "\n",
    "calculate_iou_score(target, prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
